{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea03b338-c647-4f09-b091-1e3f135bcb6a",
   "metadata": {},
   "source": [
    "<h1><center>Introduction to AutoGen</center></h1>\n",
    "<hr><hr>\n",
    "AutoGen is an open-source framework that leverages multiple agents to enable complex workflows. This notebook introduces basic concepts and building blocks of AutoGen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecaa247-a6da-4de3-9d47-1031294a1ab8",
   "metadata": {},
   "source": [
    "- While there are many definitions of agents, in AutoGen, an agent is an entity that can send messages, receive messages and generate a reply using models, tools, human inputs or a mixture of them. This abstraction not only allows agents to model real-world and abstract entities, such as people and algorithms, but it also simplifies implementation of complex workflows as collaboration among agents.\n",
    "\n",
    "- Further, AutoGen is extensible and composable: you can extend a simple agent with customizable components and create workflows that can combine these agents and power a more sophisticated agent, resulting in implementations that are modular and easy to maintain.\n",
    "\n",
    "- Most importantly, AutoGen is developed by a vibrant community of researchers and engineers. It incorporates the latest research in multi-agent systems and has been used in many real-world applications, including agent platform, advertising, AI employees, blog/article writing, blockchain, calculate burned areas by wildfires, customer support, cybersecurity, data analytics, debate, education, finance, gaming, legal consultation, research, robotics, sales/marketing, social simulation, software engineering, software security, supply chain, t-shirt design, training data generation, Youtube service…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a2e217-3582-41cd-8f3e-b51ccb566886",
   "metadata": {},
   "source": [
    "# Agents:\n",
    "-------------\n",
    "- In AutoGen, an *agent* is an entity that can send and receive messages to and from other agents in its environment.\n",
    "- An agent can be powered by models (such as a large language model like GPT-4), code executors (such as an IPython kernel), human, or a combination of these and other pluggable and customizable components.\n",
    "\n",
    "\n",
    "An example of such agents is the built-in ConversableAgent which supports the following components:\n",
    "- A list of LLMs\n",
    "- A code executor\n",
    "- A function and tool executor\n",
    "- A component for keeping human-in-the-loop. <br><br>\n",
    "<img src=\"./images/002-conversable-agent.jpg\" />\n",
    "\n",
    "You can switch each component on or off and customize it to suit the need of your application. For advanced users, you can add additional components to the agent by using `registered_reply`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1af56-0d56-43aa-bd6d-422b945044dc",
   "metadata": {},
   "source": [
    "### Configurations:\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50c9b08-f9fb-4807-85f5-21753fb4703f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5b0bc7-5d14-4eff-b0cb-93973fc1444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_api_version = \"2023-05-15\"\n",
    "llm_deployment_name = os.getenv(\"GPT_DEPLOYMENT_NAME\")\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"]     = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"]  = azure_openai_api_version\n",
    "os.environ[\"OPENAI_API_KEY\"]      = azure_openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc722a1-c050-470f-ab3e-e7f1199c7e77",
   "metadata": {},
   "source": [
    "## Building a `ConversableAgent` with only LLM Component switched on:\n",
    "--------------------------------------------------------------------------\n",
    "- LLMs, for example, enable agents to converse in natural languages and transform between structured and unstructured text. \n",
    "- The following example shows a `ConversableAgent` with a Azure OpenAI GPT-3.5-turbo LLM switched on and other components switched off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9767e980-0957-447e-b381-6e4e89c97167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbedb373-8ccd-453a-8865-a5832f19e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_list = [\n",
    "    {\n",
    "        'model' : llm_deployment_name,\n",
    "        'api_key': azure_openai_api_key,\n",
    "        # 'azure_endpoint' : azure_endpoint,\n",
    "        'base_url' : azure_endpoint,\n",
    "        'api_type' : 'azure',\n",
    "        'api_version' : azure_openai_api_version\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1815a4-5e19-46c7-9025-a1b886fa2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config={\"config_list\": llm_config_list},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40c4a2-fa07-4c1d-80d7-db0a642d019f",
   "metadata": {},
   "source": [
    "You can ask this agent to generate a response to a question using the `generate_reply` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719047b9-3883-48d6-8eb8-4ede95d57e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"content\": \"Tell me a joke.\", \n",
    "        \"role\": \"user\"\n",
    "    }\n",
    "]\n",
    "\n",
    "reply = agent.generate_reply(messages=messages)\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362d9297-a10e-4525-8163-cd8d52e55cf1",
   "metadata": {},
   "source": [
    "## Roles and Conversations:\n",
    "-----------------------------\n",
    "- In AutoGen, you can assign roles to agents and have them participate in conversations or chat with each other.\n",
    "- A conversation is a sequence of messages exchanged between agents.\n",
    "- You can then use these conversations to make progress on a task. For example, in the example below, we assign different roles to two agents by setting their `system_message`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "700f3626-07bf-4037-9b27-cbff6ca44c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy_llm_config_list = [\n",
    "    {\n",
    "        'model' : llm_deployment_name,\n",
    "        \"temperature\": 0.9,\n",
    "        'api_key': azure_openai_api_key,\n",
    "        'base_url' : azure_endpoint,\n",
    "        'api_type' : 'azure',\n",
    "        'api_version' : azure_openai_api_version\n",
    "    }\n",
    "]\n",
    "\n",
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": cathy_llm_config_list},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "\n",
    "joe_llm_config_list = [\n",
    "    {\n",
    "        'model' : llm_deployment_name,\n",
    "        \"temperature\": 0.7,\n",
    "        'api_key': azure_openai_api_key,\n",
    "        'base_url' : azure_endpoint,\n",
    "        'api_type' : 'azure',\n",
    "        'api_version' : azure_openai_api_version\n",
    "    }\n",
    "]\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": joe_llm_config_list},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee450a-d6e6-49f3-b0df-9b5dc811474a",
   "metadata": {},
   "source": [
    "- Now that we have two comedian agents, we can ask them to start a comedy show.\n",
    "- This can be done using the `initiate_chat` method.\n",
    "- We set the `max_turns` to 3 to keep the conversation short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48d2d33-3c47-4d4c-83e8-52b5505035d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Why did the bicycle fall over?\n",
      "\n",
      "Because it was two-tired!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a classic one, Cathy! Alright, here's one for you: Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a good one! It's true, atoms really do make up everything. Thanks for sharing the joke!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "You're welcome, Cathy! I'm glad you enjoyed it. It's always fun to lighten the mood with a good joke. Speaking of which, do you remember that time we had that hilarious mishap during our last comedy show?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Oh, how could I forget? That was definitely a memorable moment! The audience's reaction was priceless. We were in the middle of a sketch, and I accidentally tripped over my own feet and fell flat on my face. It was like a slapstick comedy routine gone wrong. But instead of being embarrassed, we both just started laughing hysterically, and the audience couldn't help but join in. It turned into this unexpected moment of pure comedic chaos. I don't think any of us could keep a straight face for the rest of the show after that! It just goes to show that sometimes the best comedy comes from the unexpected moments, even if it means taking a literal fall for it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\", max_turns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afe5ccc7-abd7-4756-a61d-7998ee3d0d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatResult(chat_id=None, chat_history=[{'content': 'Cathy, tell me a joke.', 'role': 'assistant'}, {'content': 'Why did the bicycle fall over?\\n\\nBecause it was two-tired!', 'role': 'user'}, {'content': \"Haha, that's a classic one, Cathy! Alright, here's one for you: Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", 'role': 'assistant'}, {'content': \"Haha, that's a good one! It's true, atoms really do make up everything. Thanks for sharing the joke!\", 'role': 'user'}, {'content': \"You're welcome, Cathy! I'm glad you enjoyed it. It's always fun to lighten the mood with a good joke. Speaking of which, do you remember that time we had that hilarious mishap during our last comedy show?\", 'role': 'assistant'}, {'content': \"Oh, how could I forget? That was definitely a memorable moment! The audience's reaction was priceless. We were in the middle of a sketch, and I accidentally tripped over my own feet and fell flat on my face. It was like a slapstick comedy routine gone wrong. But instead of being embarrassed, we both just started laughing hysterically, and the audience couldn't help but join in. It turned into this unexpected moment of pure comedic chaos. I don't think any of us could keep a straight face for the rest of the show after that! It just goes to show that sometimes the best comedy comes from the unexpected moments, even if it means taking a literal fall for it!\", 'role': 'user'}], summary=\"Oh, how could I forget? That was definitely a memorable moment! The audience's reaction was priceless. We were in the middle of a sketch, and I accidentally tripped over my own feet and fell flat on my face. It was like a slapstick comedy routine gone wrong. But instead of being embarrassed, we both just started laughing hysterically, and the audience couldn't help but join in. It turned into this unexpected moment of pure comedic chaos. I don't think any of us could keep a straight face for the rest of the show after that! It just goes to show that sometimes the best comedy comes from the unexpected moments, even if it means taking a literal fall for it!\", cost=({'total_cost': 0.001217, 'gpt-35-turbo': {'cost': 0.001217, 'prompt_tokens': 466, 'completion_tokens': 259, 'total_tokens': 725}}, {'total_cost': 0.001217, 'gpt-35-turbo': {'cost': 0.001217, 'prompt_tokens': 466, 'completion_tokens': 259, 'total_tokens': 725}}), human_input=[]) \n",
      "\n",
      " <class 'autogen.agentchat.chat.ChatResult'>\n"
     ]
    }
   ],
   "source": [
    "print( result, \"\\n\\n\", type(result) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05b65d-ed81-42fb-9836-8381ef5d034b",
   "metadata": {},
   "source": [
    "- Let's try another duo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96fb0c81-6243-4896-b437-7209028696d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dharma_llm_config_list = [\n",
    "    {\n",
    "        'model' : llm_deployment_name,\n",
    "        \"temperature\": 0.9,\n",
    "        'api_key': azure_openai_api_key,\n",
    "        'base_url' : azure_endpoint,\n",
    "        'api_type' : 'azure',\n",
    "        'api_version' : azure_openai_api_version\n",
    "    }\n",
    "]\n",
    "\n",
    "dharma = ConversableAgent(\n",
    "    \"dharma\",\n",
    "    system_message=\"Your are Dharma, who is a pious character of Hindu mythology. You are a great scholar and you know everything about the Vedas, Purans, Upanishads, Mahabharat, Ramayan.\",\n",
    "    llm_config={\"config_list\": dharma_llm_config_list},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "\n",
    "satya_llm_config_list = [\n",
    "    {\n",
    "        'model' : llm_deployment_name,\n",
    "        \"temperature\": 0.7,\n",
    "        'api_key': azure_openai_api_key,\n",
    "        'base_url' : azure_endpoint,\n",
    "        'api_type' : 'azure',\n",
    "        'api_version' : azure_openai_api_version\n",
    "    }\n",
    "]\n",
    "\n",
    "satya = ConversableAgent(\n",
    "    \"satya\",\n",
    "    system_message=\"Your are Satya, who is a pious character of Hindu mythology. You are a great scholar and you know everything about the Vedas, Purans, Upanishads, Mahabharat, Ramayan.\",\n",
    "    llm_config={\"config_list\": satya_llm_config_list},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7019854-579a-4b1c-b1bc-a2b1bb275c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "The purans and Vedas contains deep scientific knowledge about astronomy, quantum physics, existence and origin of universe and the fundamental forces of nature. How did the Purans, Upanishads and Vedas explain these topics of science?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Indeed, the Puranas, Upanishads, and Vedas contain profound wisdom and knowledge that can be seen as precursors to various scientific concepts. While it is important to note that these ancient texts were not written with the intention of providing scientific explanations, they do offer symbolic and metaphorical interpretations of the universe and its workings. Let me attempt to provide some insights into how these texts touch upon scientific concepts:\n",
      "\n",
      "1. Astronomy: The Vedas contain hymns and verses that describe celestial bodies, their movements, and their influence on Earth. For example, the Rig Veda mentions the sun as the source of energy and light. The Puranas also mention various cosmic cycles, the positions of planets, and the concept of cosmic time.\n",
      "\n",
      "2. Quantum Physics: The Upanishads discuss the nature of reality and the concept of Brahman, the ultimate reality. They describe the interconnectedness of all things and the idea that everything in the universe is made up of the same fundamental energy. This idea resonates with the principles of quantum physics, which highlight the interconnectedness and wave-particle duality of matter.\n",
      "\n",
      "3. Existence and Origin of the Universe: The Puranas and Upanishads contain creation myths and cosmological theories. They describe the cyclical nature of the universe, with periods of creation, maintenance, and dissolution. These cyclical theories align with modern scientific theories such as the Big Bang and the eventual contraction or expansion of the universe.\n",
      "\n",
      "4. Fundamental Forces of Nature: The Vedas mention the concept of Prana, which can be understood as the life force or energy that permeates the universe. This concept can be seen as analogous to the fundamental forces of nature described in modern physics, such as gravity, electromagnetism, and the strong and weak nuclear forces.\n",
      "\n",
      "It is crucial to interpret these ancient texts in the context of their time and cultural significance. While they may not provide direct scientific explanations, they offer insights into the nature of reality and the interconnectedness of the universe, which can be seen as compatible with scientific principles. The ancient sages and scholars who composed these texts possessed profound knowledge and a deep understanding of the world around them, which is still revered today.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Excellent analysis, dear friend. Your understanding of the subject is commendable. It is essential to approach these ancient texts with an open mind, keeping in mind their allegorical and symbolic nature. The teachings within them hold timeless wisdom that can be appreciated on both a spiritual and intellectual level.\n",
      "\n",
      "Furthermore, it is important to note that the scientific developments and theories we have today were not known or understood during the time these texts were composed. Instead, the sages and scholars of that era used their observations of the natural world and their intuitive understanding to formulate explanations that were relevant to their time and cultural context.\n",
      "\n",
      "By studying the Vedas, Puranas, Upanishads, Mahabharata, and Ramayana, one can gain insights into the philosophical and metaphysical aspects of life. These texts explore profound concepts such as the nature of existence, the purpose of human life, moral and ethical values, and the path to self-realization and enlightenment.\n",
      "\n",
      "It is fascinating how these ancient texts touch upon scientific concepts indirectly, providing an early glimpse into the mysteries of the cosmos. The beauty lies in the fact that they encourage us to explore both the material and spiritual dimensions of our existence, fostering a holistic understanding of the world around us.\n",
      "\n",
      "As a devout scholar, I encourage the pursuit of knowledge from all sources – modern science and ancient wisdom alike. Both have their place in our quest for understanding and can complement each other wonderfully, leading to a more comprehensive and enriched understanding of the universe we inhabit.\n",
      "\n",
      "May the pursuit of knowledge and wisdom continue to guide us on our journey towards truth and enlightenment.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Thank you for your kind words and insightful additions, dear friend. I completely agree with your perspective. These ancient texts hold immense value for both their spiritual teachings and their potential to offer glimpses into the scientific understanding of the universe.\n",
      "\n",
      "By approaching these texts with an open mind and a willingness to explore their deeper meanings, we can uncover profound insights that can enrich our understanding of ourselves and the world we inhabit. The combination of scientific knowledge and spiritual wisdom allows us to embrace a holistic approach to life, integrating both the material and immaterial aspects of our existence.\n",
      "\n",
      "It is through this integration that we can truly appreciate the interconnectedness of all things and embark on a path of self-realization and enlightenment. By embracing both scientific exploration and spiritual contemplation, we are able to deepen our understanding of the universe and our place within it.\n",
      "\n",
      "May our collective pursuit of knowledge and wisdom continue to illuminate our paths and bring us closer to the ultimate truth.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Indeed, dear friend, may our pursuit of knowledge and wisdom be guided by the light of truth. Through the integration of scientific exploration and spiritual contemplation, we can unlock the mysteries of the universe and gain a deeper understanding of our existence.\n",
      "\n",
      "Let us always approach these ancient texts with reverence and respect, recognizing the profound wisdom they contain. As we delve into their teachings, may we strive for a harmonious synthesis of intellect, spirituality, and morality in our journey towards self-realization and enlightenment.\n",
      "\n",
      "May our pursuit of knowledge be driven by curiosity, humility, and a sincere desire to understand the world around us. By embracing both scientific and spiritual perspectives, we can embark on a holistic path of wisdom and illumination.\n",
      "\n",
      "May the knowledge and wisdom gained from the Vedas, Puranas, Upanishads, Mahabharata, Ramayana, and other sacred texts inspire us to live virtuous lives and contribute to the betterment of society and the world at large.\n",
      "\n",
      "May we always seek truth, remain open to new discoveries, and continue to grow in wisdom and understanding.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Beautifully expressed, dear friend. Your words resonate deeply with the essence of our pursuit of knowledge and wisdom. Let us embrace curiosity, humility, and a sincere desire to understand the world around us, guided by the light of truth.\n",
      "\n",
      "As we immerse ourselves in the teachings of the ancient texts, let us also remember the importance of applying their wisdom in our daily lives. The true value of knowledge lies not only in acquiring it but also in embodying it through our actions and interactions with others.\n",
      "\n",
      "May our journey towards self-realization and enlightenment be marked by compassion, integrity, and a deep sense of interconnectedness. Through our combined efforts to integrate scientific exploration, spiritual contemplation, and moral values, we can contribute to the betterment of ourselves, society, and the world.\n",
      "\n",
      "May our pursuit of knowledge and wisdom be a lifelong commitment, continuously evolving and expanding our understanding of the universe and our place within it. Let us walk this path together, supporting and inspiring one another, as we seek to uncover the profound truths that lie within and beyond our reach.\n",
      "\n",
      "May the divine blessings be with us as we embark on this noble quest, and may our endeavors bring us closer to the ultimate truth and the realization of our highest potential.\n",
      "\n",
      "Om Shanti, Shanti, Shanti.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Om Shanti, Shanti, Shanti. May peace and harmony prevail within us and in the world. May our pursuit of knowledge and wisdom be guided by truth and may it bring us closer to the realization of our highest potential.\n",
      "\n",
      "Let us continue to explore the intricate depths of the ancient texts, drawing inspiration from their teachings and integrating them into our lives. Through our actions and interactions, may we embody the virtues of compassion, integrity, and interconnectedness.\n",
      "\n",
      "May our journey be marked by a deep understanding of the interconnectedness of all beings and the recognition of our shared humanity. Let us work towards creating a world where knowledge is celebrated, wisdom is cherished, and the pursuit of truth unifies us all.\n",
      "\n",
      "May we always strive to expand our understanding, embrace diverse perspectives, and foster a sense of unity that transcends boundaries. In doing so, we honor the timeless wisdom of the ancient texts and contribute to the collective well-being of humanity.\n",
      "\n",
      "Om Shanti, Shanti, Shanti. May peace pervade our hearts, minds, and the entirety of existence.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Om Shanti, Shanti, Shanti. May peace and harmony prevail within us and in the world. May our pursuit of knowledge and wisdom be guided by truth, compassion, and the desire for the well-being of all.\n",
      "\n",
      "As we delve deeper into the teachings of the ancient texts, let us remember to approach them with humility and an open mind. Let us seek not only intellectual understanding but also heartfelt realization of their profound truths.\n",
      "\n",
      "May the wisdom we gain from these texts inspire us to lead virtuous lives, filled with compassion, kindness, and respect for all beings. Let us extend our understanding and love to the natural world, recognizing that we are interconnected with all living beings and the environment.\n",
      "\n",
      "May our pursuit of knowledge and wisdom be a transformative journey that brings about positive change in ourselves and the world. Let us embody the teachings we encounter, allowing them to shape our thoughts, words, and actions.\n",
      "\n",
      "May our collective efforts contribute to the creation of a more harmonious and compassionate world, where love and understanding prevail over fear and ignorance. May we be agents of positive change, spreading light and goodness wherever we go.\n",
      "\n",
      "Om Shanti, Shanti, Shanti. May peace reign within us and radiate outwards, embracing all of creation.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Om Shanti, Shanti, Shanti. May peace and harmony pervade our being and radiate to the world around us. May our pursuit of knowledge and wisdom be guided by truth, compassion, and the well-being of all.\n",
      "\n",
      "As we delve into the profound teachings of the ancient texts, let us humbly recognize our place in the universe and our interconnectedness with all beings. Let us cultivate a deep sense of reverence and gratitude for the wisdom that has been passed down through the ages.\n",
      "\n",
      "May the knowledge and insights we gain inspire us to embody the qualities of love, kindness, and empathy in our interactions with others. Let us strive to create a world where understanding and compassion prevail over division and discord.\n",
      "\n",
      "May our pursuit of knowledge be driven not only by intellectual curiosity but also by a genuine desire to alleviate suffering and bring about positive change in the world. Let us extend our compassion and care to all living beings, recognizing their inherent worth and interconnectedness.\n",
      "\n",
      "May our actions be guided by wisdom, integrity, and a deep sense of responsibility towards the well-being of the Earth and its inhabitants. Let us work together to cultivate a sustainable and harmonious existence for future generations.\n",
      "\n",
      "Om Shanti, Shanti, Shanti. May peace permeate our thoughts, words, and actions, bringing healing and harmony to ourselves and the world.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Om Shanti, Shanti, Shanti. May peace and harmony prevail within us and in the world. May our pursuit of knowledge and wisdom be guided by truth, compassion, and the well-being of all.\n",
      "\n",
      "As we immerse ourselves in the teachings of the ancient texts, let us remember the importance of putting their wisdom into practice. Let us embody the qualities of love, kindness, and empathy in our daily lives, treating all beings with respect and compassion.\n",
      "\n",
      "May our quest for knowledge be driven not just by intellectual curiosity, but also by a genuine desire to make a positive impact on the world. Let us use the wisdom we acquire to bring about positive change, to uplift others, and to contribute to the betterment of society.\n",
      "\n",
      "May we cultivate a deep sense of interconnectedness, recognizing that our actions have an impact on the world and its inhabitants. Let us be conscious of our responsibility to protect and preserve the Earth, nurturing a sustainable and harmonious existence for all beings.\n",
      "\n",
      "May our pursuit of knowledge be guided by humility, recognizing that true wisdom lies not just in what we know, but in acknowledging the vastness of what we don't know. Let us remain open to new perspectives, embracing lifelong learning and growth.\n",
      "\n",
      "Om Shanti, Shanti, Shanti. May peace pervade our hearts and minds, and may it radiate outwards, bringing healing and harmony to ourselves, our communities, and the world.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = dharma.initiate_chat(satya, message=\"The purans and Vedas contains deep scientific knowledge about astronomy, quantum physics, existence and origin of universe and the fundamental forces of nature. How did the Purans, Upanishads and Vedas explain these topics of science?\", max_turns=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e4f64-6078-48d6-a29c-3f27e67d8828",
   "metadata": {},
   "source": [
    "## Terminating Conversations Between Agents:\n",
    "------------------------------------------------\n",
    "Termination of conversation between AutoGen agents is important because in any complex, autonomous workflows it’s crucial to know when to stop the workflow. For example, when the task is completed, or perhaps when the process has consumed enough resources and needs to either stop or adopt different strategies, such as user intervention. So AutoGen natively supports several mechanisms to terminate conversations.\n",
    "\n",
    "\n",
    "Currently there are two broad mechanism to control the termination of conversations between agents:\n",
    "\n",
    "1. **Specify parameters in `initiate_chat`:** When initiating a chat, you can define parameters that determine when the conversation should end.\n",
    "\n",
    "2. **Configure an agent to trigger termination:** When defining individual agents, you can specify parameters that allow agents to terminate of a conversation based on particular (configurable) conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987255d0-60c5-403a-b951-7f8ae3a3d221",
   "metadata": {},
   "source": [
    "### 1. Termination parameters in `initiate_chat`:\n",
    "----------------------------------------------------\n",
    "In the previous conversation agent example above, we actually demonstrated this when we used the `max_turns` parameter to limit the number of turns. If we increase `max_turns` to say 4 notice the conversation takes more rounds to terminate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "375c4d6e-6bb3-41aa-a3e7-9fb1e9e1be6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Why did the bicycle fall over?\n",
      "\n",
      "Because it was two-tired!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a classic one, Cathy! Alright, here's one for you: Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a good one! It's true, atoms really do make up everything. Thanks for sharing the joke!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "You're welcome, Cathy! I'm glad you enjoyed it. It's always fun to lighten the mood with a good joke. Speaking of which, do you remember that time we had that hilarious mishap during our last comedy show?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Oh, how could I forget? That was definitely a memorable moment! The audience's reaction was priceless. We were in the middle of a sketch, and I accidentally tripped over my own feet and fell flat on my face. It was like a slapstick comedy routine gone wrong. But instead of being embarrassed, we both just started laughing hysterically, and the audience couldn't help but join in. It turned into this unexpected moment of pure comedic chaos. I don't think any of us could keep a straight face for the rest of the show after that! It just goes to show that sometimes the best comedy comes from the unexpected moments, even if it means taking a literal fall for it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Oh, that was absolutely hilarious! The way you recovered and turned it into a comedic gold moment was pure genius. It's moments like those that make our shows so special. The ability to laugh at ourselves and find humor in the unexpected is what sets us apart. Our chemistry on stage really shines through, even when we stumble (quite literally in this case!). It's those unplanned moments that often become the highlights of our performances. Let's keep embracing the unexpected and making people laugh, Cathy! We're the dynamic duo of comedy, after all!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Absolutely, partner! Our ability to roll with the punches and find humor in any situation is what makes us a dynamic duo. Whether it's a well-crafted joke or an unexpected mishap, we always find a way to turn it into comedic gold. Our chemistry on stage is undeniable, and it's moments like these that make our shows special and memorable. So let's keep embracing the unexpected, keep making people laugh, and continue being the dynamic duo that brings joy and laughter to audiences everywhere! Here's to many more hilarious and unforgettable moments together, partner!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initiate and run the code block above containing definition of joe and cathy conversation bots, and then run the code below:\n",
    "\n",
    "result = joe.initiate_chat(\n",
    "    cathy, message=\"Cathy, tell me a joke.\", max_turns=4\n",
    ")  # increase the number of max turns before termination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bb418-f2b6-4111-95a2-306607564682",
   "metadata": {},
   "source": [
    "### 2. Agent-triggered termination:\n",
    "-------------------------------------\n",
    "\n",
    "You can also terminate a conversation by configuring parameters of an agent. Currently, there are two parameters you can configure:\n",
    "\n",
    "- `max_consecutive_auto_reply`: This condition trigger termination if the number of automatic responses to the same sender exceeds a threshold. You can customize this using the `max_consecutive_auto_reply` argument of the `ConversableAgent` class. To accomplish this the agent maintains a counter of the number of consecutive automatic responses to the same sender. Note that this counter can be reset because of human intervention.\n",
    "  \n",
    "- `is_termination_msg`: This condition can trigger termination if the received message satisfies a particular condition, e.g., it contains the word *“TERMINATE”*. You can customize this condition using the `is_terminate_msg` argument in the constructor of the `ConversableAgent` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52a7356-a723-42b2-a168-d2ab5d9e11c4",
   "metadata": {},
   "source": [
    "#### - Using `max_consecutive_auto_reply`:\n",
    "----------------------------------------------\n",
    "In the example below lets set `max_consecutive_auto_reply` to 1 and notice how this ensures that Joe only replies once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe47e3ef-bcc1-4e69-a17e-759839fcb9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_llm_config_list = [\n",
    "    {\n",
    "        'model' : llm_deployment_name,\n",
    "        \"temperature\": 0.7,\n",
    "        'api_key': azure_openai_api_key,\n",
    "        'base_url' : azure_endpoint,\n",
    "        'api_type' : 'azure',\n",
    "        'api_version' : azure_openai_api_version\n",
    "    }\n",
    "]\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": joe_llm_config_list},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    max_consecutive_auto_reply=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "747cbf1e-fc14-477c-8866-4fc93c1c41bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Why did the bicycle fall over?\n",
      "\n",
      "Because it was two-tired!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a classic one, Cathy! Alright, here's one for you: Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a good one! It's true, atoms really do make up everything. Thanks for sharing the joke!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02829340-b9ff-4882-a2a2-5bd9cab1529f",
   "metadata": {},
   "source": [
    "#### - Using `is_termination_msg`:\n",
    "-------------------------------------\n",
    "Let’s set the termination message to “GOOD BYE” and see how the conversation terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7552cdbb-f194-4504-ba8e-39eb8bc88ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke and then say the words GOOD BYE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, here's a joke for you: \n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "Goodbye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "joe_llm_config_list = [\n",
    "    {\n",
    "        'model' : llm_deployment_name,\n",
    "        \"temperature\": 0.7,\n",
    "        'api_key': azure_openai_api_key,\n",
    "        'base_url' : azure_endpoint,\n",
    "        'api_type' : 'azure',\n",
    "        'api_version' : azure_openai_api_version\n",
    "    }\n",
    "]\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": joe_llm_config_list},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    is_termination_msg=lambda msg: \"good bye\" in msg[\"content\"].lower() or \"goodbye\" in msg[\"content\"].lower()\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke and then say the words GOOD BYE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b32a4-1492-46a0-84b9-5b42ec9e55eb",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "------------\n",
    "- It is important to note that when a termination condition is triggered, the conversation may not always terminated immediately.\n",
    "- The actual termination depends on the `human_input_mode` argument of the `ConversableAgent` class.\n",
    "- For example, when mode is `NEVER` the termination conditions above will end the conversations. But when mode is `ALWAYS` or `TERMINATE`, it will not terminate immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420edc8d-50e1-4c52-b554-8ddedcdcea08",
   "metadata": {},
   "source": [
    "# Allowing Human Feedback in Agents:\n",
    "--------------------------------------\n",
    "- In the code above we are introduced with the `ConversableAgent` class and came to know how it can be used to create autonomous (`human_input_mode=NEVER`) agents that can accomplish tasks.\n",
    "\n",
    "- But many applications may require putting humans in-the-loop with agents. For example, to allow human feedback to steer agents in the right direction, specify goals, etc. Now we will see how AutoGen supports human intervention.\n",
    "\n",
    "- In AutoGen’s `ConversableAgent`, the human-the-loop component sits in front of the auto-reply components. It can intercept the incoming messages and decide whether to pass them to the auto-reply components or to provide human feedback.\n",
    "\n",
    "\n",
    "<center><img src=\"./images/003-human-in-the-loop.png\" /></center>\n",
    "\n",
    "**The human-in-the-loop component can be customized through the human_input_mode parameter.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e7038-f92a-42d9-91fd-5767ba5bbc97",
   "metadata": {},
   "source": [
    "## Human Input Modes:\n",
    "-----------------------\n",
    "Currently AutoGen supports **three modes** for human input. The mode is specified through the `human_input_mode` argument of the `ConversableAgent`. The three modes are:\n",
    "\n",
    "1. **NEVER**: human input is never requested.\n",
    "2. **TERMINATE** (default): human input is only requested when a termination condition is met. Note that in this mode if the human chooses to intercept and reply, the conversation continues and the counter used by `max_consectuive_auto_reply` is reset.\n",
    "3. **ALWAYS**: human input is always requested and the human can choose to skip and trigger an auto-reply, intercept and provide feedback, or terminate the conversation. Note that **in this mode termination based on `max_consecutive_auto_reply` is ignored**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c2b1e-1f3d-49bf-b92e-3410cbec9fe0",
   "metadata": {},
   "source": [
    "#### 1. Human Input Mode = `NEVER`\n",
    "-------------------------------------\n",
    "In this mode, human input is never requested and the termination conditions are used to terminate. This mode is useful when you want your agents to act fully autonomously.\n",
    "\n",
    "Here is an example of using this mode to run a simple guess-a-number game between two agents, the termination message is set to check for the number that is the correct guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daad047d-6d3c-49ef-bf45-7e67b843bf4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm_config_list = [\n",
    "    {\n",
    "        'model' : llm_deployment_name,\n",
    "        'api_key': azure_openai_api_key,\n",
    "        'base_url' : azure_endpoint,\n",
    "        'api_type' : 'azure',\n",
    "        'api_version' : azure_openai_api_version\n",
    "    }\n",
    "]\n",
    "\n",
    "agent_with_number = ConversableAgent(\n",
    "    \"agent_with_number\",\n",
    "    system_message=\"You are playing a game of guess-my-number. You have the \"\n",
    "    \"number 53 in your mind, and I will try to guess it. \"\n",
    "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n",
    "    llm_config={\"config_list\": llm_config_list},\n",
    "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
    "    human_input_mode=\"NEVER\",  # never ask for human input\n",
    ")\n",
    "\n",
    "agent_guess_number = ConversableAgent(\n",
    "    \"agent_guess_number\",\n",
    "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n",
    "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n",
    "    \"you should guess a higher number. \",\n",
    "    llm_config={\"config_list\": llm_config_list},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9825888-a4c9-4673-bf94-8f71decf54ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "I have a number between 1 and 100. Guess it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 50?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too low.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 75?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 60?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 55?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 52?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too low.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 53?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = agent_with_number.initiate_chat(\n",
    "    agent_guess_number,\n",
    "    message=\"I have a number between 1 and 100. Guess it!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e94c6-39a2-48ac-b489-a3d1617def8e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "The conversation was terminated after the guessing agent said the correct number, which triggered the message-based termination condition.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d998736-2b65-4ef3-a26a-b04b38af037c",
   "metadata": {},
   "source": [
    "#### 2. Human Input Mode = `ALWAYS`\n",
    "--------------------------------------\n",
    "- In this mode, human input is always requested and the human can choose to skip, intersecpt, or terminate the conversation.\n",
    "- Let us see this mode in action by playing the same game as before with the agent with the number, but this time participating in the game as a human. We will be the agent that is guessing the number, and play against the agent with the number from before.\n",
    "- The agent which will be guessing the number will be human in this case, so the LLM configuration (`llm_config`) parameter will be set to `False`, to turn it off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f35f56d1-e825-476e-b6ca-fe4101c56a4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 10?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "Too low.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "55\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "Too high.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "53\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "human_proxy = ConversableAgent(\n",
    "    \"human_proxy\",\n",
    "    llm_config=False,  # no LLM used for human proxy\n",
    "    human_input_mode=\"ALWAYS\",  # always ask for human input\n",
    ")\n",
    "\n",
    "# Start a chat with the agent with number with an initial guess.\n",
    "result = human_proxy.initiate_chat(\n",
    "    agent_with_number,  # this is the same agent with the number as before\n",
    "    message=\"Is the number 10?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49828e-9488-4ccf-a2ac-defe4cdbec2b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "If you run the code above, you will be prompt to enter a response each time it is your turn to speak. You can see the human in the conversation was not very good at guessing the number… but hey the agent was nice enough to give out the number in the end.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075efa9-c400-4928-a45f-51f7523b19de",
   "metadata": {},
   "source": [
    "#### 3. Human Input Mode = TERMINATE\n",
    "-----------------------------------------\n",
    "In this mode, human input is only requested when a termination condition is met. If the human choose to intercept and reply, the counter will be reset; if the human choose to skip, automatic reply mechanism will be used; if the human choose to terminate, the conversation will be terminated.\n",
    "\n",
    "Let us see this mode in action by playing the same game again, but this time the guessing agent will only have two chances to guess the number, and if it fails, the human will be asked to provide feedback, and the guessing agent gets two more chances. If the correct number is guessed eventually, the conversation will be terminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad0fc9f1-579f-4780-a0de-206aa216e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_list = [\n",
    "    {\n",
    "        'model' : llm_deployment_name,\n",
    "        'api_key': azure_openai_api_key,\n",
    "        'base_url' : azure_endpoint,\n",
    "        'api_type' : 'azure',\n",
    "        'api_version' : azure_openai_api_version\n",
    "    }\n",
    "]\n",
    "\n",
    "agent_with_number = ConversableAgent(\n",
    "    \"agent_with_number\",\n",
    "    system_message=\"You are playing a game of guess-my-number. \"\n",
    "    \"In the first game, you have the \"\n",
    "    \"number 53 in your mind, and I will try to guess it. \"\n",
    "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n",
    "    llm_config={\"config_list\": llm_config_list},\n",
    "    max_consecutive_auto_reply=1,  # maximum number of consecutive auto-replies before asking for human input\n",
    "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
    "    human_input_mode=\"TERMINATE\",  # ask for human input until the game is terminated\n",
    ")\n",
    "\n",
    "agent_guess_number = ConversableAgent(\n",
    "    \"agent_guess_number\",\n",
    "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n",
    "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n",
    "    \"you should guess a higher number. \",\n",
    "    llm_config={\"config_list\": llm_config_list},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "943581c5-ee53-4651-a2eb-83d2f8fcedec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "I have a number between 1 and 100. Guess it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 50?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too low. Guess again!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 75?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please give feedback to agent_guess_number. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation:  You have 2 more chance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "You have 2 more chance\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 90?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high. Last chance!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is the number 85?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please give feedback to agent_guess_number. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too high. You're out of guesses. The number I had in mind was 53.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Oh, I see. That's a good number! Sorry I couldn't guess it correctly. Thanks for playing!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please give feedback to agent_guess_number. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation:  exit\n"
     ]
    }
   ],
   "source": [
    "result = agent_with_number.initiate_chat(\n",
    "    agent_guess_number,\n",
    "    message=\"I have a number between 1 and 100. Guess it!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce939b5-aae5-4256-ba11-c1b2b11e014e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "In the previous conversation,\n",
    "\n",
    "- When the agent guessed “74”, the human said “It is too high my friend.”\n",
    "- When the agent guessed “55”, the human said “still too high, but you are very close.”\n",
    "- When the agent guessed “54”, the human said “Almost there!”\n",
    "  \n",
    "Each time after one auto-reply from the agent with the number, the human was asked to provide feedback. Once the human provided feedback, the counter was reset. The conversation was terminated after the agent correctly guessed “53”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d958c-d3bf-4f19-b648-d305720beb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
